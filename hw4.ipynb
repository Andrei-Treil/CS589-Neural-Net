{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict,Counter\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self,nodes,lamb=0.0,alpha=0.1,eps=0.0):\n",
    "        '''\n",
    "        Constructor for neural net\n",
    "        nodes - list detailing number of nodes in each layer\n",
    "        lamb - regularization\n",
    "        alpha - learning rate\n",
    "        eps - cost function stopping condition\n",
    "        '''\n",
    "        self.nodes = nodes\n",
    "        self.lamb = lamb\n",
    "        self.alpha = alpha\n",
    "        self.weights = []\n",
    "        self.eps = eps\n",
    "        #initialize weights for each layer, include bias\n",
    "        for i in range(len(nodes)-1):\n",
    "            self.weights.append(np.random.normal(0,1,(nodes[i]+1,nodes[i+1])).T)\n",
    "    \n",
    "    def get_sigmoid(self, x):\n",
    "        return 1 / (1+np.exp(-x))\n",
    "    \n",
    "    def deriv_sigmoid(self, x):\n",
    "        return x * (1-x)\n",
    "\n",
    "    def train(self, features, targs, for_exam=False):\n",
    "        prev_cost = math.inf\n",
    "        gradients = [0]*len(self.weights)\n",
    "        num_inst = len(targs)\n",
    "        keep_learn = True\n",
    "        count = 1\n",
    "\n",
    "        while(keep_learn):\n",
    "            J = 0\n",
    "            for instance,target in zip(features,targs):\n",
    "                #iterate through layers, vectorize forward pass\n",
    "                activations = [np.atleast_2d(instance)]\n",
    "                for i in range(len(self.weights)-1):\n",
    "                    try:\n",
    "                        this_a = self.get_sigmoid(self.weights[i].dot(activations[i].T))\n",
    "                    except:\n",
    "                        this_a = self.get_sigmoid(self.weights[i].T.dot(activations[i].T))\n",
    "                    activations.append(np.insert(this_a,0,1))\n",
    "                try:\n",
    "                    activations.append(self.get_sigmoid(activations[len(self.weights)-1].dot(self.weights[len(self.weights)-1])))\n",
    "                except:\n",
    "                    activations.append(self.get_sigmoid(activations[len(self.weights)-1].dot(self.weights[len(self.weights)-1].T)))\n",
    "                guess = activations[-1]\n",
    "\n",
    "                #accumulate sum loss\n",
    "                target = np.array(target)\n",
    "                cost = np.sum((np.array(-target)).dot(np.log(guess)) - (np.array(1-target)).dot(np.log(1-guess)))\n",
    "                J += cost\n",
    "\n",
    "                #begin backwards propogation\n",
    "                error = guess - target\n",
    "                delta_inst = [error]\n",
    "\n",
    "                #get delta values for all weights on current instance\n",
    "                for i in range(len(self.weights)-1, 0, -1):\n",
    "                    try:\n",
    "                        this_del = (self.weights[i].T.dot(delta_inst[-1])) * self.deriv_sigmoid(activations[i].T)\n",
    "                    except:\n",
    "                        #this_del = (self.weights[i].T*(delta_inst[-1])) * self.deriv_sigmoid(activations[i])\n",
    "                        this_del = (self.weights[i].dot(delta_inst[-1])) * self.deriv_sigmoid(activations[i].T)\n",
    "                        #delta_inst.append(this_del[0][1:])\n",
    "                    delta_inst.append(this_del[1:])\n",
    "\n",
    "                #reverse delta values\n",
    "                delta_inst = delta_inst[::-1]\n",
    "\n",
    "                #accumulate gradients\n",
    "                for i in range(len(self.weights)-1,-1,-1):\n",
    "                    try:\n",
    "                        gradients[i] += (delta_inst[i]*(activations[i].T)).T\n",
    "                    except:\n",
    "                        gradients[i] += (np.atleast_2d(delta_inst[i]).T*np.atleast_2d(activations[i].T))\n",
    "\n",
    "                #print for examples\n",
    "                if for_exam:\n",
    "                    print(f'OUTPUTS FOR INSTANCE {count}')\n",
    "                    print(f'activations: ')\n",
    "                    for i in range(len(activations)):\n",
    "                        print(f'a{i+1}: {activations[i]}')\n",
    "                    print()\n",
    "                    print(f'prediction: {guess}')\n",
    "                    print(f'expected: {target}')\n",
    "                    print(f'cost J: {cost}')\n",
    "                    print()\n",
    "                    print('delta for this instance: ')\n",
    "                    for i in range(len(delta_inst)):\n",
    "                        print(f'delta {i+2}: {delta_inst[i]}')\n",
    "                    print()\n",
    "                    print('gradients for this instance: ')\n",
    "                    for i in range(len(self.weights)):\n",
    "                        try:\n",
    "                            print_del = (delta_inst[i]*(activations[i].T)).T\n",
    "                        except:\n",
    "                            print_del = (np.atleast_2d(delta_inst[i]).T*np.atleast_2d(activations[i].T)).T\n",
    "                        print(f'theta {i+1}: {print_del}')\n",
    "                    print()\n",
    "                    count += 1\n",
    "            \n",
    "            #regularize weights and update\n",
    "            for i in range(len(self.weights)-1,-1,-1):\n",
    "                P = self.lamb * (self.weights[i])\n",
    "                #set first column to all 0\n",
    "                P[:,0] = 0\n",
    "                try:\n",
    "                    gradients[i] = gradients[i] + P.T\n",
    "                except:\n",
    "                    gradients[i] = gradients[i] + P\n",
    "                gradients[i] = gradients[i] / num_inst\n",
    "                learn_diff = self.alpha * (gradients[i])\n",
    "                try:\n",
    "                    self.weights[i] = self.weights[i] - learn_diff\n",
    "                except:\n",
    "                    self.weights[i] = self.weights[i] - learn_diff.T\n",
    "\n",
    "            J /= num_inst\n",
    "            curr_s = 0\n",
    "            for i in range(len(self.weights)):\n",
    "                curr_s += np.sum(self.weights[i][1:]**2)\n",
    "\n",
    "            #curr_s = np.sum(self.weights[1:]**2)\n",
    "            curr_s *= (self.lamb/(2*num_inst))\n",
    "            new_cost = J + curr_s\n",
    "\n",
    "            #if improvement in cost is less than epsilon, stop\n",
    "            if prev_cost - new_cost < self.eps:\n",
    "                keep_learn = False\n",
    "\n",
    "            prev_cost = new_cost\n",
    "\n",
    "            if for_exam:\n",
    "                print('regularized gradients: ')\n",
    "                for i in range(len(gradients)):\n",
    "                    print(f'theta {i+1}: {gradients[i]}')\n",
    "                keep_learn = False\n",
    "\n",
    "\n",
    "    def predict(self,instance):\n",
    "        \n",
    "        activations = [np.atleast_2d(instance)]\n",
    "        for i in range(len(self.weights)-1):\n",
    "            try:\n",
    "                this_a = self.get_sigmoid(self.weights[i].dot(activations[i].T))\n",
    "            except:\n",
    "                this_a = self.get_sigmoid(self.weights[i].T.dot(activations[i].T))\n",
    "            activations.append(np.insert(this_a,0,1))\n",
    "        try:\n",
    "            activations.append(self.get_sigmoid(activations[len(self.weights)-1].dot(self.weights[len(self.weights)-1])))\n",
    "        except:\n",
    "            activations.append(self.get_sigmoid(activations[len(self.weights)-1].dot(self.weights[len(self.weights)-1].T)))\n",
    "        guess = activations[-1]\n",
    "        pred = [0]*len(guess)\n",
    "        pred[np.argmax(guess)] = 1\n",
    "        \n",
    "        #TODO: check for argmax\n",
    "        return pred\n",
    "       \n",
    "        #pred = np.atleast_2d(instance)\n",
    "        #for i in range(len(self.weights)):\n",
    "            #pred = self.get_sigmoid(pred.dot(self.weights[i].T))\n",
    "        \n",
    "        #return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_decision(nn,test_set,vals):\n",
    "    to_guess = pd.DataFrame(test_set,copy=True)\n",
    "    to_guess['class'] = 1\n",
    "    predictions = pd.DataFrame(to_guess.apply(lambda row: nn.predict(row.to_numpy()), axis=1),columns=['predicted'])\n",
    "    predictions['actual'] = test_set.loc[predictions.index,'class']\n",
    "    prec,rec,f1 = [0,0,0]\n",
    "\n",
    "    for val in vals:\n",
    "        is_targ = predictions[predictions.predicted.apply(lambda x: x == val)]\n",
    "        not_targ = predictions[predictions.predicted.apply(lambda x: x != val)]\n",
    "        tp = len(is_targ[is_targ['predicted'] == is_targ['actual']])\n",
    "        fp = len(is_targ[is_targ['predicted'] != is_targ['actual']])\n",
    "        fn = len(not_targ[not_targ.actual.apply(lambda x: x == val)])\n",
    "        tn = len(not_targ[not_targ.actual.apply(lambda x: x != val)])\n",
    "        this_prec = (tp/(tp+fp)) if (tp+fp) > 0 else 0\n",
    "        this_rec = (tp/(tp+fn)) if (tp+fn) > 0 else 0\n",
    "        f1 += (this_prec*this_rec*2)/(this_rec+this_prec) if (this_rec+this_prec) > 0 else 0\n",
    "        prec += this_prec\n",
    "        rec += this_rec\n",
    "\n",
    "    #avg_prec = prec/len(vals)\n",
    "    #avg_rec = rec/len(vals)\n",
    "    avg_f1 = f1/len(vals)\n",
    "    accuracy = len(predictions[predictions['predicted'] == predictions['actual']])/len(test_set)\n",
    "    return accuracy,avg_f1\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "k = 10\n",
    "#list of neural net architectures\n",
    "nn_arc = [[13,4,3],[13,8,3],[13,4,8,3],[13,8,16,3],[13,2,4,8,3],[13,2,4,8,4,3]]\n",
    "wine_df = pd.read_csv('datasets/hw3_wine.csv',delimiter='\\t')\n",
    "norm_wine_df = ((wine_df-wine_df.min())/(wine_df.max()-wine_df.min()))\n",
    "\n",
    "#split data by class into k groups then combine into folds\n",
    "wine_class_1 = norm_wine_df.loc[norm_wine_df['class'] == 0].sample(frac=1)\n",
    "wine_class_1['class'] = [[1,0,0]]*len(wine_class_1)\n",
    "wc1_split = np.array_split(wine_class_1,k)\n",
    "wine_class_2 = norm_wine_df.loc[norm_wine_df['class'] == 0.5].sample(frac=1)\n",
    "wine_class_2['class'] = [[0,1,0]]*len(wine_class_2)\n",
    "wc2_split = np.array_split(wine_class_2,k)\n",
    "wine_class_3 = norm_wine_df.loc[norm_wine_df['class'] == 1].sample(frac=1)\n",
    "wine_class_3['class'] = [[0,0,1]]*len(wine_class_3)\n",
    "wc3_split = np.array_split(wine_class_3,k)\n",
    "wine_vals = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "\n",
    "#list to hold folds\n",
    "wine_fold = []\n",
    "for i in range(k):\n",
    "    this_fold = [wc1_split[i],wc2_split[i],wc3_split[i]]\n",
    "    wine_fold.append(pd.concat(this_fold))\n",
    "\n",
    "#function to do cross fold validation\n",
    "def k_fold(fold,vals):\n",
    "    #maps n vals to list of average statistics for each \n",
    "    fold_metrics = defaultdict(list)\n",
    "    #iterate through folds, taking turns being test fold\n",
    "    for i in range(k):\n",
    "        test_fold = fold[i]\n",
    "        train_fold = fold[0:i]\n",
    "        train_fold.extend(fold[i+1:len(fold)])\n",
    "        train_data = pd.concat(train_fold)\n",
    "        #insert column of ones to act as bias\n",
    "        train_data.insert(0,'bias',1)\n",
    "        #iterate through architectures\n",
    "        for arc in nn_arc:\n",
    "            np_targs = train_data['class'].to_numpy()\n",
    "            np_inst = train_data.drop('class',axis=1).to_numpy()\n",
    "            this_nn = NeuralNet(arc,lamb=0.5,eps=0.001,alpha=1)\n",
    "            this_nn.train(np_inst,np_targs)\n",
    "            fold_metrics[str(arc)].append(test_decision(this_nn,test_fold,vals))\n",
    "            \n",
    "    return fold_metrics\n",
    "\n",
    "res = k_fold(wine_fold,wine_vals)\n",
    "print(':3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: [13, 4, 3], Accuracy: 0.97218782249742, F1: 0.9736441336441336\n",
      "Architecture: [13, 8, 3], Accuracy: 0.9718954248366014, F1: 0.9728360528360529\n",
      "Architecture: [13, 4, 8, 3], Accuracy: 0.9166322669418644, F1: 0.8979052059052058\n",
      "Architecture: [13, 8, 16, 3], Accuracy: 0.6884696422428621, F1: 0.6070748098837343\n",
      "Architecture: [13, 2, 4, 8, 3], Accuracy: 0.5582817337461301, F1: 0.38684894698620187\n",
      "Architecture: [13, 2, 4, 8, 4, 3], Accuracy: 0.3992539559683522, F1: 0.190154052603328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Architecture  Accuracy        F1\n",
      "0           [13, 4, 3]  0.972188  0.973644\n",
      "1           [13, 8, 3]  0.971895  0.972836\n",
      "2        [13, 4, 8, 3]  0.916632  0.897905\n",
      "3       [13, 8, 16, 3]  0.688470  0.607075\n",
      "4     [13, 2, 4, 8, 3]  0.558282  0.386849\n",
      "5  [13, 2, 4, 8, 4, 3]  0.399254  0.190154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\_pydev_imports_tipper.py:205: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  obj = getattr(obj_to_complete, d)\n"
     ]
    }
   ],
   "source": [
    "arc_dict = defaultdict(list)\n",
    "\n",
    "for arc,perf in res.items():\n",
    "    avg_acc,avg_f1 = [0,0]\n",
    "    for arr in perf:\n",
    "        avg_acc += arr[0]\n",
    "        avg_f1 += arr[1]\n",
    "    arc_dict['Architecture'].append(arc)\n",
    "    arc_dict['Accuracy'].append(avg_acc/10)\n",
    "    arc_dict['F1'].append(avg_f1/10)\n",
    "\n",
    "arc_table = pd.DataFrame(arc_dict)\n",
    "print(arc_table)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Correctness Verification**\n",
    "\n",
    "Below I have included 2 functions: ```train_on_first()``` and ```train_on_sec()```\n",
    "\n",
    "These functions hard code the inputs and print the desired outputs to stdout. If the output is too large for your IDE, set the max lines of your output to 100. To run these functions, simply call them without arguement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS FOR INSTANCE 1\n",
      "activations: \n",
      "a1: [[1.   0.13]]\n",
      "a2: [1.        0.601807  0.5807858]\n",
      "a3: [0.79402743]\n",
      "\n",
      "prediction: [0.79402743]\n",
      "expected: [0.9]\n",
      "cost J: 0.36557477431084995\n",
      "\n",
      "delta for this instance: \n",
      "delta 2: [-0.01269739 -0.01548092]\n",
      "delta 3: [-0.10597257]\n",
      "\n",
      "gradients for this instance: \n",
      "theta 1: [[-0.01269739 -0.00165066]\n",
      " [-0.01548092 -0.00201252]]\n",
      "theta 2: [-0.10597257 -0.06377504 -0.06154737]\n",
      "\n",
      "OUTPUTS FOR INSTANCE 2\n",
      "activations: \n",
      "a1: [[1.   0.42]]\n",
      "a2: [1.         0.60873549 0.59483749]\n",
      "a3: [0.79596607]\n",
      "\n",
      "prediction: [0.79596607]\n",
      "expected: [0.23]\n",
      "cost J: 1.2763768066887786\n",
      "\n",
      "delta for this instance: \n",
      "delta 2: [0.06739994 0.08184068]\n",
      "delta 3: [0.56596607]\n",
      "\n",
      "gradients for this instance: \n",
      "theta 1: [[0.06739994 0.02830797]\n",
      " [0.08184068 0.03437309]]\n",
      "theta 2: [0.56596607 0.34452363 0.33665784]\n",
      "\n",
      "regularized gradients: \n",
      "theta 1: [[0.02735127 0.01332866]\n",
      " [0.03317988 0.01618028]]\n",
      "theta 2: [[0.22999675 0.1403743  0.13755523]]\n"
     ]
    }
   ],
   "source": [
    "#function to train on backprop_example1.txt\n",
    "#outputs to stdout, if full output cannot be viewed when calling this function, increase number of lines shown in output to 100\n",
    "def train_on_first():\n",
    "\ttrain_nn = NeuralNet([1,2,1],eps=0.001)\n",
    "\ttrain_nn.weights[0] = np.array([[0.40000,0.10000 ],[0.30000,0.20000 ]])\n",
    "\ttrain_nn.weights[1] = np.array([[0.7],[0.5],[0.6]])\n",
    "\ttrain_set_1 = {'x': [0.13000,0.42000], 'y': [0.90000,0.23000]}\n",
    "\t#NOTE: X values are preprocessed to include bias term (1) as first element\n",
    "\tX = np.array([[1,0.13000],[1,0.42000]])\n",
    "\tY = np.array([[0.90000],[0.23000]])\n",
    "\ttrain_df = pd.DataFrame(data=train_set_1)\n",
    "\ttrain_df.insert(0,'bias',np.ones)\n",
    "\ttrain_nn.train(X,Y,True)\n",
    "\n",
    "train_on_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS FOR INSTANCE 1\n",
      "activations: \n",
      "a1: [[1.   0.32 0.68]]\n",
      "a2: [1.         0.67699586 0.75384029 0.5881687  0.70566042]\n",
      "a3: [1.         0.87519469 0.89296181 0.81480444]\n",
      "a4: [0.83317658 0.84131543]\n",
      "\n",
      "prediction: [0.83317658 0.84131543]\n",
      "expected: [0.75 0.98]\n",
      "cost J: 0.7907366961135718\n",
      "\n",
      "delta for this instance: \n",
      "delta 2: [-0.00086743 -0.00133354 -0.00053312 -0.00070163]\n",
      "delta 3: [ 0.00638937 -0.00925379 -0.00778767]\n",
      "delta 4: [ 0.08317658 -0.13868457]\n",
      "\n",
      "gradients for this instance: \n",
      "theta 1: [[-0.00086743 -0.00027758 -0.00058985]\n",
      " [-0.00133354 -0.00042673 -0.00090681]\n",
      " [-0.00053312 -0.0001706  -0.00036252]\n",
      " [-0.00070163 -0.00022452 -0.00047711]]\n",
      "theta 2: [[ 0.00638937 -0.00925379 -0.00778767]\n",
      " [ 0.00432557 -0.00626478 -0.00527222]\n",
      " [ 0.00481656 -0.00697588 -0.00587066]\n",
      " [ 0.00375802 -0.00544279 -0.00458046]\n",
      " [ 0.00450872 -0.00653003 -0.00549545]]\n",
      "theta 3: [[ 0.08317658 -0.13868457]\n",
      " [ 0.0727957  -0.121376  ]\n",
      " [ 0.07427351 -0.12384003]\n",
      " [ 0.06777264 -0.1130008 ]]\n",
      "\n",
      "OUTPUTS FOR INSTANCE 2\n",
      "activations: \n",
      "a1: [[1.   0.83 0.02]]\n",
      "a2: [1.         0.63471542 0.69291867 0.54391158 0.64659376]\n",
      "a3: [1.         0.86020091 0.88336451 0.79790763]\n",
      "a4: [0.82952703 0.83831889]\n",
      "\n",
      "prediction: [0.82952703 0.83831889]\n",
      "expected: [0.75 0.28]\n",
      "cost J: 1.9437823352945294\n",
      "\n",
      "delta for this instance: \n",
      "delta 2: [0.01694006 0.01465141 0.01998824 0.01622017]\n",
      "delta 3: [0.01503437 0.05808969 0.06891698]\n",
      "delta 4: [0.07952703 0.55831889]\n",
      "\n",
      "gradients for this instance: \n",
      "theta 1: [[0.01694006 0.01406025 0.0003388 ]\n",
      " [0.01465141 0.01216067 0.00029303]\n",
      " [0.01998824 0.01659024 0.00039976]\n",
      " [0.01622017 0.01346274 0.0003244 ]]\n",
      "theta 2: [[0.01503437 0.05808969 0.06891698]\n",
      " [0.00954254 0.03687042 0.04374267]\n",
      " [0.01041759 0.04025143 0.04775386]\n",
      " [0.00817737 0.03159565 0.03748474]\n",
      " [0.00972113 0.03756043 0.04456129]]\n",
      "theta 3: [[0.07952703 0.55831889]\n",
      " [0.06840922 0.48026642]\n",
      " [0.07025135 0.4931991 ]\n",
      " [0.06345522 0.44548691]]\n",
      "\n",
      "regularized gradients: \n",
      "theta 1: [[0.00803632 0.02564134 0.04987447]\n",
      " [0.00665894 0.01836697 0.06719311]\n",
      " [0.00972756 0.03195982 0.05251862]\n",
      " [0.00775927 0.05036911 0.08492365]]\n",
      "theta 2: [[0.01071187 0.09068406 0.02511708 0.1259677  0.11586492]\n",
      " [0.02441795 0.06780282 0.04163777 0.05307643 0.1267652 ]\n",
      " [0.03056466 0.08923522 0.1209416  0.10270214 0.03078292]]\n",
      "theta 3: [[0.0813518  0.17935246 0.12476243 0.13186393]\n",
      " [0.20981716 0.19194521 0.30342954 0.25249305]]\n"
     ]
    }
   ],
   "source": [
    "#function to train on backprop_example2.txt\n",
    "#outputs to stdout, if full output cannot be viewed when calling this function, increase number of lines shown in output to 100\n",
    "def train_on_sec():\n",
    "\ttrain_nn = NeuralNet([2,4,3,2],eps=0.001,lamb=0.250)\n",
    "\ttrain_nn.weights[0] = np.array([[0.42000,0.15000,0.40000],[0.72000,0.10000,0.54000],[0.01000,0.19000,0.42000],[0.30000,0.35000,0.68000]])\n",
    "\ttrain_nn.weights[1] = np.array([[0.21000,0.67000,0.14000,0.96000,0.87000],[0.87000,0.42000,0.20000,0.32000,0.89000],[0.03000,0.56000,0.80000,0.69000,0.09000]])\n",
    "\ttrain_nn.weights[2] = np.array([[0.04000,0.87000,0.42000,0.53000],[0.17000,0.10000,0.95000,0.69000]])\n",
    "\ttrain_set_1 = {'x': [0.13000,0.42000], 'y': [0.90000,0.23000]}\n",
    "\t#NOTE: X values are preprocessed to include bias term (1) as first element\n",
    "\tX = np.array([[1,0.32000,0.68000],[1,0.83000,0.02000]])\n",
    "\tY = np.array([[0.75000,0.98000],[0.75000,0.28000]])\n",
    "\ttrain_nn.train(X,Y,True)\n",
    "\n",
    "#train_on_first()\n",
    "train_on_sec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eee\n"
     ]
    }
   ],
   "source": [
    "testy = 1\n",
    "print('eee')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
